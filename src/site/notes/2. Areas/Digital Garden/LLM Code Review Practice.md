---
{"dg-publish":true,"permalink":"/2-areas/digital-garden/llm-code-review-practice/","tags":["Action/TODO"],"created":"2025-04-17T19:56:00","updated":"2025-04-17 19:56"}
---


**I. 利用 LLM 进行 Code Review 的最佳实践**

1. **明确目标和范围 (Define Scope & Goals):**
   - **不要求全责备:** 不要期望 LLM 能像经验丰富的人类审查者那样理解复杂的业务逻辑、项目架构或长期维护性。
   - **设定具体任务:** 让 LLM 专注于它可以做得相对较好的方面，例如：
     - **语法和风格检查:** 检查是否符合 PEP 8、Google Style Guide 等规范。
     - **查找常见错误模式:** 如潜在的空指针异常、资源未释放、常见的安全漏洞（如 SQL 注入、XSS 的基本模式）、低效循环等。
     - **代码简化和可读性建议:** 提出重构建议，使代码更简洁、命名更清晰。
     - **文档和注释生成/检查:** 检查注释是否与代码匹配，或根据代码生成初步的文档字符串。
     - **测试用例建议:** 基于代码逻辑建议可能的边缘测试用例。
   - **小块代码审查:** 最好将代码分解成函数、类或小的 Pull Request diff 进行审查，而不是一次性扔给它整个文件或项目。

2. **精心设计提示 (Prompt Engineering):**
   - **提供上下文:** 清晰说明代码的语言、使用的框架、主要目的或功能。如果可能，提供相关的代码片段或接口定义。
   - **指定审查标准:** 明确告知 LLM 你关心的方面（"请检查这段 Python 代码是否符合 PEP 8 规范，并找出潜在的性能问题。"）。
   - **扮演角色:** 让 LLM 扮演特定角色（"Act as a senior software engineer reviewing this code for potential bugs and security vulnerabilities."）。
   - **要求具体格式输出:** 要求 LLM 以列表、表格或带代码建议的方式给出反馈，便于阅读和处理（"List potential issues with severity (High/Medium/Low) and suggest fixes with code examples."）。
   - **迭代提问:** 如果反馈不清晰或不完整，追问具体细节（"Can you explain why this is a potential issue?" "Can you provide an alternative implementation?"）。

3. **整合到工作流 (Integrate Wisely):**
   - **预审查 (Pre-Review):** 在提交给人类审查者之前，先用 LLM 进行一轮审查，修复明显的、低层次的问题，节省人类审查者的时间。
   - **辅助审查 (Augmented Review):** 人类审查者可以参考 LLM 的意见，但重点关注更高层次的逻辑、设计和业务契合度。
   - **自动化工具:** 使用集成 LLM 功能的工具（如 GitHub Copilot in the CLI/IDE, CodeRabbit, Bito AI 等），简化提问和应用建议的过程。

4. **批判性思维和验证 (Critical Thinking & Verification):**
   - **绝不盲从:** LLM 的建议可能是错误的、不适用的，甚至引入新的问题（幻觉）。**必须**理解建议背后的原因。
   - **验证建议:** 对于 LLM 提出的修改建议，务必在本地运行、测试，确保其正确性、性能没有下降，并且符合项目需求。
   - **关注“为什么”:** 不仅看建议是什么，更要理解为什么 LLM 会这么建议。这本身就是学习过程。
   - **安全审查尤其谨慎:** LLM 对安全漏洞的检测能力有限，特别是对于复杂或新型的漏洞。不能完全依赖 LLM 进行安全审计。

**II. 从 LLM Code Review 中学习和提升的最佳实践**

1. **深入分析反馈 (Analyze Feedback Deeply):**
   - **分类整理:** 将 LLM 的反馈归类（风格、Bug、性能、可读性、安全等）。
   - **探究根源:** 对于指出的问题，思考为什么这是一种不好的实践？它违反了哪些设计原则（如 SOLID、DRY）？可能导致什么后果？
   - **研究建议方案:** 理解 LLM 提供的替代方案为何更好？它使用了哪些不同的技术或模式？

2. **主动提问和探索 (Ask Follow-up Questions):**
   - **“教我”模式:** 把 LLM 当作一个（有时会犯错的）导师。提出深入的问题：
     - "请解释这个设计模式的优缺点。"
     - "这段代码还有哪些其他的优化方法？各自的取舍是什么？"
     - "这个错误类型在什么情况下容易发生？如何系统性地避免？"
     - "你能用更简单的语言解释这段复杂逻辑吗？"
   - **比较不同方案:** 让 LLM 生成多种解决方案，并分析它们的差异。

3. **对比人类反馈 (Compare with Human Review):**
   - **寻找差异:** 注意人类审查者和 LLM 反馈的不同之处。人类通常更关注架构、业务逻辑和长期影响，而 LLM 可能更擅长发现模式化的细节错误。
   - **学习人类的视角:** 理解为什么人类审查者提出了 LLM 没有发现的问题，这有助于培养更高层次的设计思维。

4. **实践和实验 (Practice & Experiment):**
   - **尝试应用建议:** 在安全的环境（如新分支）中，尝试应用 LLM 的重构或优化建议，观察代码的变化和测试结果。
   - **刻意练习:** 如果 LLM 反复指出你在某方面（如错误处理、异步编程）存在问题，将其视为学习重点，主动寻找相关资料并进行练习。

5. **反思和总结 (Reflect & Summarize):**
   - **记录学习:** 定期记录从 LLM Code Review 中学到的新知识、设计模式或常见陷阱。
   - **改进提示:** 通过实践，学习如何更有效地向 LLM 提问以获得高质量的反馈，这本身也是一种提升。
   - **生成解释:** 让 LLM 解释你自己写的代码，看它是否能准确理解。如果不能，可能意味着你的代码不够清晰，需要改进。

**总结:**

将 LLM 用于 Code Review 的核心是**增强而非替代**人类审查者。将其视为一个强大的、不知疲倦的、但需要仔细引导和验证的助手。通过主动分析其反馈、深入提问、对比人类意见并动手实践，你可以有效地利用 LLM 加速学习过程，识别自身知识盲点，并逐步提升编码的规范性、健壮性和效率。

将大型语言模型（LLM）融入代码审查流程，不仅可以提高审查效率，还能成为程序员学习和提升编码能力的强大工具。以下是一些利用 LLM 进行代码审查并从中学习和提升编码能力的最佳实践：

**一、  LLM 在代码审查中的角色和优势**

- **自动化初步审查:** LLM 可以快速扫描代码，自动化执行一些重复性和低价值的审查任务，例如：
  - **风格检查:** 遵循代码风格指南（PEP 8, Google Style Guide 等）。
  - **潜在错误检测:**  识别可能的语法错误、拼写错误、简单的逻辑漏洞、未处理的异常、潜在的安全风险（如 SQL 注入、XSS）。
  - **代码复杂度分析:** 标记高复杂度代码块，提示需要进一步人工审查。
  - **重复代码检测:** 识别代码库中的重复代码片段。
  - **依赖项和库的合规性检查:**  （在特定场景下，可能检查使用的库是否符合项目规范）。

- **提供快速反馈:** LLM 可以在代码提交后立即提供初步审查结果，让开发者尽早发现并修复问题，缩短反馈循环。

- **一致性和客观性:** LLM 的审查标准一致且客观，避免了人工审查中可能出现的主观性和疏漏。

- **学习资源和建议:**  一些 LLM 不仅能指出问题，还能提供解释、示例代码，甚至链接到相关的文档和最佳实践，成为学习的辅助工具。

**二、  利用 LLM 进行代码审查的最佳实践**

1. **明确 LLM 的定位：辅助而非替代**

   - **LLM 是助手，不是最终仲裁者:**  LLM 的审查结果应被视为建议，最终的代码质量和决策仍由人工审查员和开发者负责。
   - **专注于 LLM 的优势领域:** 利用 LLM 处理自动化、重复性的检查，让人工审查员专注于更复杂、需要领域知识和创造性的审查任务，例如：
     - **架构设计审查:**  评估代码在高层次上的设计是否合理、可扩展、可维护。
     - **业务逻辑审查:**  确保代码正确地实现了业务需求，并处理了各种边界情况。
     - **性能瓶颈分析:**  深入分析代码的性能，找出潜在的瓶颈。
     - **用户体验和可访问性审查:**  评估代码对用户体验和可访问性的影响。

2. **精细化 Prompt 工程 (Prompt Engineering)**

   - **定制化审查指令:**  根据项目需求和代码审查重点，设计具体的 prompt 指令，例如：
     - "请审查这段 Python 代码，重点关注潜在的安全漏洞和性能问题。"
     - "请检查这段 JavaScript 代码是否符合 Airbnb JavaScript Style Guide。"
     - "请分析这段 Java 代码的圈复杂度，并指出复杂度过高的函数。"
   - **提供上下文信息:**  向 LLM 提供代码的上下文信息，例如：
     - 代码所属模块和功能。
     - 项目的代码风格指南。
     - 项目的架构设计原则。
     - 代码变更的目的和背景。
   - **迭代优化 Prompt:**  根据 LLM 的审查结果，不断调整和优化 prompt，提高审查的准确性和有效性。
   - **使用结构化 Prompt:**  例如，使用 JSON 或 YAML 格式的 Prompt 来明确指定审查的范围、标准、输出格式等。

3. **集成 LLM 到代码审查流程中**

   - **CI/CD 集成:**  将 LLM 代码审查工具集成到持续集成/持续交付 (CI/CD) 流程中，在代码提交或合并请求 (Merge Request/Pull Request) 时自动触发审查。
   - **IDE 插件:**  使用 IDE 插件，在编码过程中实时进行代码审查，提供即时反馈。
   - **代码审查平台集成:**  将 LLM 集成到现有的代码审查平台（如 GitHub, GitLab, Bitbucket）中，作为审查工作流的一部分。

4. **人工审查与 LLM 审查相结合**

   - **先 LLM 后人工:**  先使用 LLM 进行初步审查，过滤掉一些低级错误和风格问题，然后由人工审查员进行更深入的审查。
   - **LLM 辅助人工审查:**  在人工审查过程中，使用 LLM 作为辅助工具，例如：
     - 对特定代码片段进行更深入的分析和解释。
     - 提供替代方案或优化建议。
     - 快速查找相关的文档或最佳实践。
   - **双重验证:**  对于 LLM 标记出的高风险或复杂问题，人工审查员需要进行重点验证和确认。

5. **持续学习和反馈循环**

   - **审查 LLM 的审查结果:**  人工审查员需要审查 LLM 的审查结果，判断其是否准确、合理，并提供反馈，帮助 LLM 改进审查能力。
   - **记录和分析 LLM 的审查效果:**  跟踪 LLM 在代码审查中的表现，例如：
     - 发现的 Bug 数量和类型。
     - 误报率和漏报率。
     - 节省的人工审查时间。
   - **定期更新和微调 LLM:**  根据项目代码库的变化和新的编程最佳实践，定期更新和微调 LLM 的模型或规则，保持审查的有效性。

**三、  从 LLM 代码审查中学习和提升编码能力**

1. **认真对待 LLM 的反馈:**  即使是自动化工具的反馈，也值得仔细阅读和思考。LLM 标记的问题往往代表了一些通用的编码规范、最佳实践或潜在风险。

2. **理解 "为什么" 比 "是什么" 更重要:**  不仅仅关注 LLM 指出的 "错误是什么"，更要深入理解 "为什么这是一个错误" 或 "为什么这样做更好"。

3. **将 LLM 的建议转化为行动:**

   - **修复 Bug 和改进代码:**  根据 LLM 的反馈，及时修复代码中的 Bug 和风格问题。
   - **学习新的编程知识:**  当 LLM 提到一些你不熟悉的编程概念、模式、库或安全漏洞时，主动去学习和研究。
   - **反思自己的编码习惯:**  如果 LLM 频繁指出你代码中存在的某类问题，反思自己的编码习惯，并有意识地改进。

4. **主动探索 LLM 提供的学习资源:**  如果 LLM 提供了相关的文档链接、示例代码或最佳实践，积极去阅读和学习，扩展自己的知识面。

5. **与 LLM 进行 "对话" (Prompt Engineering 的进阶应用):**

   - **提问和澄清:**  如果对 LLM 的审查结果有疑问，可以通过 prompt 向 LLM 提问，例如：
     - "请详细解释为什么这里存在安全风险。"
     - "请提供一个更简洁的实现方案。"
     - "请给出符合 SOLID 原则的重构建议。"
   - **请求代码示例:**  让 LLM 生成符合特定规范或最佳实践的代码示例，作为学习的参考。
   - **对比不同方案:**  让 LLM 分析和比较不同的代码实现方案，帮助你理解各种方案的优缺点。

6. **将 LLM 代码审查作为持续学习的工具:**  将 LLM 集成到日常的开发流程中，持续接收反馈，不断学习和提升编码能力。

**四、  注意事项和潜在挑战**

- **LLM 的局限性:**  目前的 LLM 在代码理解和推理方面仍然存在局限性，可能会出现误报、漏报，或者无法理解复杂的业务逻辑和上下文。
- **数据隐私和安全:**  在使用云端 LLM 服务进行代码审查时，需要注意代码的隐私和安全问题，选择可靠的服务提供商，并采取必要的安全措施。
- **过度依赖 LLM:**  避免过度依赖 LLM，失去人工审查的价值，特别是对于架构设计、业务逻辑、用户体验等需要深入思考和领域知识的方面。
- **工具选择和集成成本:**  选择合适的 LLM 代码审查工具，并将其集成到现有开发流程中，可能需要一定的成本和技术投入。
- **持续维护和更新:**  为了保证 LLM 代码审查的有效性，需要进行持续的维护、更新和微调。

**总结**

利用 LLM 进行代码审查是提升代码质量和开发效率的有效手段。通过合理的应用和实践，LLM 不仅可以辅助代码审查工作，更能成为程序员学习和提升编码能力的宝贵资源。关键在于将 LLM 定位为辅助工具，精细化 Prompt 工程，结合人工审查，并持续学习和反馈，才能最大化 LLM 的价值，并克服其局限性。
